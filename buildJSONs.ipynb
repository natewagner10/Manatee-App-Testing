{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "buildJSONs.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAoZR3wmmC3X"
      },
      "source": [
        "Mount Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-OEx3ZP6Dzb",
        "outputId": "a42ea6bd-7629-4d3d-fb5f-1c0c8be6a409"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv21HqRVmFcW"
      },
      "source": [
        "Set File Paths:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIqGKgq46hBc"
      },
      "source": [
        "path_to_mrcnn = '/content/drive/MyDrive/AI/maskrcnn_files/Mask_RCNN/mrcnn/'\n",
        "path_to_model = '/content/drive/MyDrive/AI/mask_rcnn_scar_finder_713map.h5'\n",
        "path_to_all_images = '/content/drive/MyDrive/AI/data/all_images/'\n",
        "path_to_save_annotations = '/content/drive/MyDrive/AI/data/predicted_annotations2/'\n",
        "path_to_outline_poly = '/content/drive/MyDrive/AI/data/BLANK_SKETCH_updated.jpg.json'"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE581fmxmHqm"
      },
      "source": [
        "Import Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0AMBjEB6G2G",
        "outputId": "0cd24486-8b32-4a5c-eb65-0ce99a6b80d8"
      },
      "source": [
        "import random\n",
        "import json\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "import skimage\n",
        "import time\n",
        "from numpy import asarray\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "from shapely.geometry import Polygon\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycXhe5ep6G4k"
      },
      "source": [
        "import sys\n",
        "sys.path.append(path_to_mrcnn)\n",
        "\n",
        "from config import Config\n",
        "import visualize\n",
        "from utils import Dataset\n",
        "import model as modellib\n",
        "import utils\n",
        "from model import log"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-SBe4JsmKwu"
      },
      "source": [
        "Set Model Configurations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy2TRWUp6G6_",
        "outputId": "10d9f782-be5d-4632-d03c-02b038c0f430"
      },
      "source": [
        "class CustomConfig(Config):\n",
        "    \"\"\"Configuration for training on the dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    \"\"\"Configuration for training on the dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    NAME = \"scar_finder\"      \n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "    NUM_CLASSES = 3    # Background + Scar + Mute\n",
        "    STEPS_PER_EPOCH = 100\n",
        "    DETECTION_MIN_CONFIDENCE = 0.50    \n",
        "    MAX_GT_INSTANCES = 120    \n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)    \n",
        "    LOSS_WEIGHTS = {'rpn_class_loss': 1.0,\n",
        "                    'rpn_bbox_loss': 1.0,\n",
        "                    'mrcnn_class_loss': 1.0,\n",
        "                    'mrcnn_bbox_loss': 1.0,\n",
        "                    'mrcnn_mask_loss': 1.0}\n",
        "    LEARNING_RATE = 0.001   \n",
        "    MEAN_PIXEL = [248.56, 248.56, 248.56]\n",
        "    IMAGE_MIN_DIM = 512\n",
        "    IMAGE_MAX_DIM = 512\n",
        "    RPN_NMS_THRESHOLD=0.99  \n",
        "print('done')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orBXHW9xmN6h"
      },
      "source": [
        "Initialize Model and Load Weights:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVE2HNgj6G9r"
      },
      "source": [
        "config = CustomConfig()\n",
        "#Loading the model in the inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=path_to_model)\n",
        "# loading the trained weights o the custom dataset\n",
        "model.load_weights(path_to_model, by_name=True)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gXUPmrEmR0U"
      },
      "source": [
        "Extract Scar Information From Images:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYHc1rvu6RCD"
      },
      "source": [
        "def extractScarInfoAI(path_to_image, poly_outline):    \n",
        "    # set up image for model\n",
        "    new = Image.new('RGB', (512, 512), 0)\n",
        "    im = cv2.imread(path_to_image, cv2.IMREAD_GRAYSCALE)\n",
        "    im = cv2.resize(im, (256,559), interpolation = cv2.INTER_LINEAR)\n",
        "    im = Image.fromarray(im)\n",
        "    im=im.convert('RGB')\n",
        "    im=im.resize((234, 512))\n",
        "    new.paste(im, (139,0))\n",
        "    new_arr = np.asarray(new)\n",
        "\n",
        "    # run model\n",
        "    results = model.detect([new_arr], verbose=1)\n",
        "    r = results[0]\n",
        "\n",
        "    # resize image back to original\n",
        "    new_im = new_arr[0:512,139:373]\n",
        "    new_im = cv2.resize(new_im, (256,559), interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "    polys = []\n",
        "    classes = []    \n",
        "    for i in range(0, r['masks'].shape[2]):\n",
        "        img_gray = r['masks'][:,:,i]      \n",
        "        mask = img_gray[0:512,139:373]       \n",
        "        mask = mask.astype(np.uint8)  #convert to an unsigned byte\n",
        "        mask*=255\n",
        "        mask = cv2.resize(mask, (256,559), interpolation = cv2.INTER_LINEAR)\n",
        "        contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
        "        if contours[0] != []:            \n",
        "            if len(contours[0][0]) < 5:\n",
        "                contours = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
        "            area = cv2.contourArea(contours[0][0])             \n",
        "            pts = contours[0][0]\n",
        "            poly_obj = Polygon(pts.reshape((pts.shape[0], 2)))            \n",
        "            if len(contours[0]) != 0 and area > 5 and poly_outline.contains(poly_obj) == True:   \n",
        "                polys.append(contours[0])\n",
        "                classes.append(r['class_ids'][i])    \n",
        "    if len(polys) != r['masks'].shape[2]:\n",
        "        print(\"Warning, more polygons then mask\")    \n",
        "    annots_json = {}\n",
        "    annots_json['description'] = ''\n",
        "    annots_json['tags'] = []\n",
        "    annots_json['size'] = {'height': new_im.shape[0], 'width': new_im.shape[1]}\n",
        "    objects = []\n",
        "    for i in range(0,len(polys)):\n",
        "        f = {}\n",
        "        f['id'] = i+1\n",
        "        f['classId'] = 2876852\n",
        "        f['description'] = ''\n",
        "        f['geometryType'] = 'polygon'\n",
        "        f['labelerLogin'] = 'natewag10'\n",
        "        f['createdAt'] = time.asctime()\n",
        "        f['updatedAt'] = time.asctime()\n",
        "        f['tags'] = []\n",
        "        if classes[i] == 1:\n",
        "            f['classTitle'] = 'Scar'\n",
        "        elif classes[i] == 2:\n",
        "            f['classTitle'] = 'Mute'\n",
        "        pt = []        \n",
        "        for p in polys[i][0]:\n",
        "            pt.append(list(map(int, p[0])))                \n",
        "        f['points'] = {'exterior': pt, 'interior': []}\n",
        "\n",
        "        num_contours = 0\n",
        "        bb_info = []   \n",
        "        contour = np.array(pt)\n",
        "        x, y, w, h = cv2.boundingRect(contour)                          \n",
        "        area = cv2.contourArea(contour)        \n",
        "        if area > 5:\n",
        "            (x,y), (ma,MA), angle = cv2.fitEllipseDirect(contour)   \n",
        "            if MA == 0:\n",
        "                MA = 1\n",
        "            aspect_ratio = float(ma)/MA                  \n",
        "        f['orientation'] = round(angle,2)\n",
        "        f['length'] = round(MA,2)\n",
        "        f['width'] = round(ma,2)\n",
        "        f['aspect'] = round(aspect_ratio,2)\n",
        "        objects.append(f)   \n",
        "    annots_json['num_scars'] = len(polys)    \n",
        "    annots_json['objects'] = objects  \n",
        "    if 2 in classes:\n",
        "        annots_json['has_mute'] = 1\n",
        "    else:\n",
        "        annots_json['has_mute'] = 0\n",
        "    return [os.path.basename(path_to_image), polys, classes, new_im, annots_json]\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hJYMHdj6REm"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "f = open(path_to_outline_poly)\n",
        "data = json.load(f)\n",
        "pts = data['objects'][0]['points']['exterior']\n",
        "poly_outline = Polygon(np.array(pts))\n",
        "\n",
        "all_ims = os.listdir(path_to_all_images)\n",
        "failed = []\n",
        "completed = []\n",
        "for j in all_ims:\n",
        "    if j[-1] == 'g' or j[-1] == 'G':\n",
        "        try:\n",
        "            path_to_image, polys, classes, new_im, annots_json = extractScarInfoAI(path_to_all_images + j, poly_outline)\n",
        "            with open(path_to_save_annotations + j + '.json', 'w') as json_file:\n",
        "                json.dump(annots_json, json_file) \n",
        "            completed.append(j)          \n",
        "        except:\n",
        "            print(\"FAILED: \" + j) \n",
        "            failed.append(j)  \n",
        "print (\"Completed in: \", round((time.time() - start_time)/60, 2), ' minutes.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCFjifIzmXws"
      },
      "source": [
        "Check if Any Failed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecJotubf6RHH",
        "outputId": "5ca0c319-ef65-4f28-ce0c-1c2a97a05224"
      },
      "source": [
        "print(failed)\n",
        "print(len(completed))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "2640\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}